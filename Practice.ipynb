{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da3976b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95759d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #bash\n",
    "# export GOOGLE_API_KEY=\"AIzaSyAwUMBYIYXFQP300g6mSK8tpY42kN4FiM8\"\n",
    "\n",
    "# #windows powershell\n",
    "# setx GOOGLE_API_KEY \"AIzaSyAwUMBYIYXFQP300g6mSK8tpY42kN4FiM8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ded613f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(profile={'max_input_tokens': 1048576, 'max_output_tokens': 65536, 'image_inputs': True, 'audio_inputs': True, 'pdf_inputs': True, 'video_inputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'image_tool_message': True, 'tool_choice': True}, google_api_key=SecretStr('**********'), model='gemini-2.5-flash-lite', temperature=0.0, client=<google.genai.client.Client object at 0x000001A7ECA8E2A0>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAwUMBYIYXFQP300g6mSK8tpY42kN4FiM8\"\n",
    "model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\", temperature = 0.0)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b130d31",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46198e",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ca1ad70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intantiate prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template_string = template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42a55a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\", additional_kwargs={}, response_metadata={})]\n",
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} response_metadata={}\n",
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "text = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "format_message = prompt_template.format_messages(style= style,text = text)\n",
    "print(format_message)\n",
    "print(format_message[0])\n",
    "\n",
    "print(type(format_message))\n",
    "print(type(format_message[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30fa7630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Oh dear, I'm quite upset that my blender lid came off and splattered my kitchen walls with smoothie! To make matters even worse, the warranty doesn't cover the cost of cleaning up my kitchen. I really need your help right now.\" additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019b1b66-0ba8-7020-8b56-feb399333a59-0' usage_metadata={'input_tokens': 85, 'output_tokens': 51, 'total_tokens': 136, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(format_message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84fc167",
   "metadata": {},
   "source": [
    "# Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99eac29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58cf3258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['format_instructions', 'text'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'text'], input_types={}, partial_variables={}, template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\ntext: {text}\\n\\n{format_instructions}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(review_template_2)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "014496f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    gift_schema: str = Field(\n",
    "        description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\"\n",
    "    )\n",
    "    delivery_days_schema: str = Field(\n",
    "        description=\"How many days did it take for the product to arrive? If not found, output -1.\"\n",
    "    )\n",
    "    price_value_schema: str = Field(\n",
    "        description=\"Extract sentences about value or price, as a comma separated Python list.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0a7df26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Runnable.get_prompts of JsonOutputParser(pydantic_object=<class '__main__.OutputSchema'>)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=OutputSchema)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "# print(format_instructions)\n",
    "\n",
    "output_parser.get_prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2cda0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife\\'s anniversary present. I think my wife liked it so much she was speechless. So far I\\'ve been the only one using it, and I\\'ve been using it every other morning to clear the leaves on our lawn. It\\'s slightly more expensive than the other leaf blowers out there, but I think it\\'s worth it for the extra features.\\n\\n\\nSTRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only â€” do not include any backticks or Markdown in your output):\\n```\\n{\"properties\": {\"gift_schema\": {\"description\": \"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\", \"title\": \"Gift Schema\", \"type\": \"string\"}, \"delivery_days_schema\": {\"description\": \"How many days did it take for the product to arrive? If not found, output -1.\", \"title\": \"Delivery Days Schema\", \"type\": \"string\"}, \"price_value_schema\": {\"description\": \"Extract sentences about value or price, as a comma separated Python list.\", \"title\": \"Price Value Schema\", \"type\": \"string\"}}, \"required\": [\"gift_schema\", \"delivery_days_schema\", \"price_value_schema\"]}\\n```\\n', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# messages = prompt_template.format_messages(text=customer_review, format_instructions=format_instructions)\n",
    "# print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea7f69e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\"gift_schema\": \"True\", \"delivery_days_schema\": \"2\", \"price_value_schema\": \"[\\'It\\'s slightly more expensive than the other leaf blowers out there, but I think it\\'s worth it for the extra features.\\']\"}' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019b1ba3-20e9-7390-8cd3-88a46f474c6f-0' usage_metadata={'input_tokens': 611, 'output_tokens': 57, 'total_tokens': 668, 'input_token_details': {'cache_read': 0}}\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='{\"gift_schema\": \"True\", \"delivery_days_schema\": \"2\", \"price_value_schema\": \"[\\'It\\'s slightly more expensive than the other leaf blowers out there, but I think it\\'s worth it for the extra features.\\']\"}', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019b1ba3-20e9-7390-8cd3-88a46f474c6f-0', usage_metadata={'input_tokens': 611, 'output_tokens': 57, 'total_tokens': 668, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(messages)\n",
    "\n",
    "print(response)\n",
    "print(type(response))\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5373a111",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fea499",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Blob' from 'langchain_core.documents' (C:\\Users\\ChaudharyVimal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_core\\documents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Blob\n\u001b[32m      3\u001b[39m blob = Blob.from_data(\u001b[33m\"\u001b[39m\u001b[33mHello, world!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Read the blob as a string\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Blob' from 'langchain_core.documents' (C:\\Users\\ChaudharyVimal\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\langchain_core\\documents\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Blob\n",
    "\n",
    "blob = Blob.from_data(\"Hello, world!\")\n",
    "\n",
    "# Read the blob as a string\n",
    "print(blob.as_string())\n",
    "\n",
    "# Read the blob as bytes\n",
    "print(blob.as_bytes())\n",
    "\n",
    "# Read the blob as a byte stream\n",
    "with blob.as_bytes_io() as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c8b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343e355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
